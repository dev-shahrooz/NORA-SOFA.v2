# import os
# import sys
# import json
# import time
# import signal
# import threading
# import traceback
# from vosk import Model, KaldiRecognizer
# import sounddevice as sd
# import socketio
# from websocket_client import (
#     _emit,
#     add_control_listener,
#     add_state_listener,
#     request_state,
# )

# HERE = os.path.dirname(os.path.abspath(__file__))
# if HERE not in sys.path:
#     sys.path.append(HERE)

# # ØªÙ†Ø¸ÛŒÙ…Ø§Øª
# MODEL_PATH = os.path.join(HERE, "model")
# RATE = 16000
# BLOCKSIZE = 4000
# CHANNELS = 1
# WAKE_WORD = "nora"
# COMMAND_TIMEOUT_SEC = 5
# FINAL_SILENCE_MS = 1200

# wake_word_enabled = True
# _wake_lock = threading.Lock()
# _manual_listen_event = threading.Event()


# def _set_wake_word_enabled(enabled: bool) -> bool:
#     global wake_word_enabled
#     enabled = bool(enabled)
#     with _wake_lock:
#         if wake_word_enabled != enabled:
#             wake_word_enabled = enabled
#             status = "ENABLED" if enabled else "DISABLED"
#             print(f"[VA] Wake word {status} via remote control")
#         return wake_word_enabled


# def _on_state_update(state: dict):
#     try:
#         va_cfg = (state or {}).get("voice_assistant", {})
#         _set_wake_word_enabled(va_cfg.get("wake_word_enabled", True))
#     except Exception as exc:
#         print("[VA] Failed to parse state update:", exc)


# def _on_control_event(message: dict):
#     msg_type = (message or {}).get("type")
#     if msg_type == "listen_once":
#         print("[VA] Manual listen requested from UI")
#         _manual_listen_event.set()
#     elif msg_type == "wake_word" and "enabled" in message:
#         _set_wake_word_enabled(message.get("enabled", True))


# # Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù¾Ø§Ø±Ø³Ø±
# try:
#     from command_parser import handle_command, COMMANDS
# except Exception as e:
#     print("[FATAL] Cannot import command_parser:", e)
#     sys.exit(1)


# def _as_bytes(chunk):
#     """Ensure bytes for Vosk (fix cffi buffer issue)."""
#     # Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ bytes/bytearray Ù‡Ø³ØªØŒ Ù‡Ù…ÙˆÙ†Ùˆ Ø¨Ø¯Ù‡Ø› ÙˆÚ¯Ø±Ù†Ù‡ ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†
#     if isinstance(chunk, (bytes, bytearray)):
#         return chunk
#     try:
#         # Ø®ÛŒÙ„ÛŒ Ø§Ø² Ø¢Ø¨Ø¬Ú©Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§ÙØ±Ù¾Ø°ÛŒØ± Ø¨Ø§ memoryview.tobytes Ø¯Ø±Ø³Øª Ù…ÛŒâ€ŒØ´Ù†
#         return memoryview(chunk).tobytes()
#     except Exception:
#         return bytes(chunk)


# def build_wake_recognizer(model: Model) -> KaldiRecognizer:
#     grammar = json.dumps([WAKE_WORD])
#     rec = KaldiRecognizer(model, RATE, grammar)
#     try:
#         rec.SetWords(True)
#         rec.SetMaxAlternatives(0)
#     except Exception:
#         pass
#     print("[ASR] Wake grammar active:", grammar)
#     return rec


# def build_command_recognizer(model: Model) -> KaldiRecognizer:
#     phrases = list(COMMANDS.keys())
#     grammar = json.dumps(phrases)
#     rec = KaldiRecognizer(model, RATE, grammar)
#     try:
#         rec.SetWords(True)
#         rec.SetMaxAlternatives(0)
#     except Exception:
#         pass
#     print("[ASR] Strict grammar active:", grammar)
#     return rec


# def listen_command_exact(rec: KaldiRecognizer, stream_read, timeout_sec=COMMAND_TIMEOUT_SEC, silence_ms=FINAL_SILENCE_MS) -> str:
#     start = time.time()
#     last_voice_time = start
#     time.sleep(0.35)  # Ú©Ù…ÛŒ Ø¨ÛŒØ´ØªØ± Ø¨Ø±Ø§ÛŒ Ø¬Ø¯Ø§ Ø´Ø¯Ù† ØªÙ‡â€ŒÛŒ wake
#     try:
#         rec.Reset()
#     except Exception:
#         pass

#     exact_set = set(COMMANDS.keys())
#     best_text = ""  # Ø¢Ø®Ø±ÛŒÙ† Ù…ØªÙ† ØºÛŒØ±Ø®Ø§Ù„ÛŒ Ú©Ù‡ Ú¯Ø±ÙØªÛŒÙ… (ØµØ±ÙØ§Ù‹ Ø¨Ø±Ø§ÛŒ Ù„Ø§Ú¯)

#     while True:
#         data, _ = stream_read(BLOCKSIZE)
#         if not data:
#             if time.time() - start > timeout_sec:
#                 break
#             continue

#         buf = _as_bytes(data)
#         accepted = rec.AcceptWaveform(buf)
#         now = time.time()

#         if accepted:
#             res = json.loads(rec.Result())
#             txt = (res.get("text") or "").strip()
#             if txt:
#                 best_text = txt
#                 last_voice_time = now
#                 if txt in exact_set:  # âœ… Ø¨Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ø¹Ø¨Ø§Ø±Ø§Øª Ø¯Ù‚ÛŒÙ‚ Ø±Ø³ÛŒØ¯ÛŒÙ…
#                     return txt

#             # Ø§Ú¯Ø± Ø³Ú©ÙˆØª Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø´Ø¯ Ùˆ Ù‡Ù†ÙˆØ² exact Ù†Ø´Ø¯ØŒ Ø®Ø±ÙˆØ¬ÛŒ ÙØ¹Ù„ÛŒ Ø±Ùˆ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯ÙˆÙ†ÛŒÙ…
#             if (now - last_voice_time) * 1000 >= silence_ms:
#                 return txt

#         else:
#             pres = json.loads(rec.PartialResult())
#             ptxt = (pres.get("partial") or "").strip()
#             if ptxt:
#                 last_voice_time = now
#                 # partial Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ú©Ø§Ù…Ù„ Ù†ÛŒØ³ØªØ› Ø¨Ø±Ø§ÛŒ exact Ú†Ú© Ù†Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…

#         if now - start > timeout_sec:
#             break

#     # ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª: Ø¢Ø®Ø±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
#     final = json.loads(rec.FinalResult()).get("text", "").strip()
#     return final or best_text


# def main():
#     if not os.path.isdir(MODEL_PATH):
#         print(f"[FATAL] Model not found at: {MODEL_PATH}")
#         sys.exit(1)

#     print("Loading Vosk model...", MODEL_PATH)
#     model = Model(MODEL_PATH)

#     stream = sd.RawInputStream(
#         samplerate=RATE,
#         blocksize=BLOCKSIZE,
#         dtype='int16',
#         channels=CHANNELS,
#     )
#     stream.start()

#     def _sigint_handler(sig, frame):
#         print("\n[EXIT] Interrupted.")
#         try:
#             stream.stop()
#             stream.close()
#         except Exception:
#             pass
#         sys.exit(0)
#     signal.signal(signal.SIGINT, _sigint_handler)

#     print("ğŸ¤ Say something... (say 'nora' to wake)")
#     add_state_listener(_on_state_update)
#     add_control_listener(_on_control_event)
#     request_state()

#     wake_rec = build_wake_recognizer(model)
#     listening_now = False

#     def run_command_session(trigger_label: str = ""):
#         nonlocal wake_rec, listening_now
#         listening_now = True
#         try:
#             if trigger_label:
#                 print(trigger_label)
#             rec_cmd = build_command_recognizer(model)
#             cmd_text = listen_command_exact(
#                 rec_cmd,
#                 stream.read,
#                 timeout_sec=COMMAND_TIMEOUT_SEC,
#                 silence_ms=FINAL_SILENCE_MS,
#             )
#             print("ğŸ“¥ Full command (strict):",
#                   cmd_text if cmd_text else "<empty>")

#             matched = handle_command(cmd_text)
#             if matched:
#                 print("âœ… exact command executed")
#             else:
#                 print("âŒ not an exact command (ignored)")
#         finally:
#             listening_now = False
#             wake_rec = build_wake_recognizer(model)

#     while True:
#         try:
#             if _manual_listen_event.is_set() and not listening_now:
#                 _manual_listen_event.clear()
#                 run_command_session("ğŸ§ Listening (UI request)")
#                 continue

#             data, _ = stream.read(BLOCKSIZE)
#             if not data:
#                 continue

#             buf = _as_bytes(data)                  # ğŸ‘ˆ ØªØ¨Ø¯ÛŒÙ„ Ù‚Ø·Ø¹ÛŒ Ø¨Ù‡ bytes
#             if not wake_word_enabled:
#                 continue

#             if wake_rec.AcceptWaveform(buf):
#                 res = json.loads(wake_rec.Result())
#                 txt = (res.get("text") or "").strip()

#                 if txt == WAKE_WORD:
#                     print(f"ğŸ”” Wake word detected: {WAKE_WORD}")
#                     run_command_session()

#         except KeyboardInterrupt:
#             _sigint_handler(None, None)
#         except Exception as e:
#             print("[ERROR] Main loop exception:", e)
#             traceback.print_exc()
#             time.sleep(0.2)


# if __name__ == "__main__":
#     main()


import os
import sys
import json
import time
import signal
import threading
import traceback
from vosk import Model, KaldiRecognizer
import sounddevice as sd
import socketio
from websocket_client import (
    _emit,
    add_control_listener,
    add_state_listener,
    request_state,
)

HERE = os.path.dirname(os.path.abspath(__file__))
if HERE not in sys.path:
    sys.path.append(HERE)

# ---------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ASR/Audio ----------
MODEL_PATH = os.path.join(HERE, "model")
RATE = 16000
CHANNELS = 1
# blocksize Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ 16kHz ~100ms. Ø¯Ø± fallbackÙ‡Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¯ÛŒÚ¯Ø± Ù‡Ù… ØªØ³Øª Ù…ÛŒâ€ŒØ´ÙˆØ¯.
BLOCKSIZE = 1600
DTYPE = "int16"

# ---------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Wake/Command ----------
WAKE_WORD = "nora"
COMMAND_TIMEOUT_SEC = 5
FINAL_SILENCE_MS = 1200

wake_word_enabled = True
_wake_lock = threading.Lock()
_manual_listen_event = threading.Event()


def _set_wake_word_enabled(enabled: bool) -> bool:
    global wake_word_enabled
    enabled = bool(enabled)
    with _wake_lock:
        if wake_word_enabled != enabled:
            wake_word_enabled = enabled
            status = "ENABLED" if enabled else "DISABLED"
            print(f"[VA] Wake word {status} via remote control")
        return wake_word_enabled


def _on_state_update(state: dict):
    try:
        va_cfg = (state or {}).get("voice_assistant", {})
        _set_wake_word_enabled(va_cfg.get("wake_word_enabled", True))
    except Exception as exc:
        print("[VA] Failed to parse state update:", exc)


def _on_control_event(message: dict):
    msg_type = (message or {}).get("type")
    if msg_type == "listen_once":
        print("[VA] Manual listen requested from UI")
        _manual_listen_event.set()
    elif msg_type == "wake_word" and "enabled" in message:
        _set_wake_word_enabled(message.get("enabled", True))


# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù¾Ø§Ø±Ø³Ø±
try:
    from command_parser import handle_command, COMMANDS
except Exception as e:
    print("[FATAL] Cannot import command_parser:", e)
    sys.exit(1)


# ---------- Ú©Ù…Ú©ÛŒâ€ŒÙ‡Ø§ÛŒ ØµÙˆØª ----------
def _as_bytes(chunk):
    """Ensure bytes for Vosk (fix cffi buffer issue)."""
    if isinstance(chunk, (bytes, bytearray)):
        return chunk
    try:
        return memoryview(chunk).tobytes()
    except Exception:
        return bytes(chunk)


def _pick_input_device() -> int | None:
    """
    ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ ÙˆØ±ÙˆØ¯ÛŒ PulseØ› Ø§Ú¯Ø± Ù†Ø¨ÙˆØ¯ØŒ None (ÛŒØ¹Ù†ÛŒ default).
    """
    try:
        devs = sd.query_devices()
        # Ø§ÙˆÙ„ÙˆÛŒØª: Ø¯Ø³ØªÚ¯Ø§Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§ Ù†Ø§Ù… pulse
        for i, d in enumerate(devs):
            name = str(d.get("name", "")).lower()
            if d.get("max_input_channels", 0) > 0 and "pulse" in name:
                print(f"[AUDIO] Selected input via Pulse: idx={i}, name={d['name']}")
                return i
        # Ø§Ú¯Ø± pulse Ù†Ø¨ÙˆØ¯ØŒ default Ø±Ø§ Ø¨Ø³Ù¾Ø§Ø± Ø¨Ù‡ PortAudio/pipewire
        print("[AUDIO] No 'pulse' device found; using default input device.")
        return None
    except Exception as e:
        print("[AUDIO] Device query failed, falling back to default:", e)
        return None


def _open_input_stream():
    """
    Ø§Ø³ØªØ±ÛŒÙ… ÙˆØ±ÙˆØ¯ÛŒ Ø±Ø§ Ø¨Ø§ Ú†Ù†Ø¯ ØªÙ„Ø§Ø´ Ø¨Ø§Ø² Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø¨Ø§ PipeWire/Pulse Ø³Ø§Ø²Ú¯Ø§Ø± Ø´ÙˆØ¯.
    """
    input_device = _pick_input_device()

    attempts = [
        dict(blocksize=BLOCKSIZE, latency="low"),
        dict(blocksize=800, latency="high"),
        dict(blocksize=None, latency="high"),  # Ø¨Ú¯Ø°Ø§Ø± PortAudio ØªØµÙ…ÛŒÙ… Ø¨Ú¯ÛŒØ±Ø¯
    ]

    last_err = None
    for idx, opts in enumerate(attempts, start=1):
        try:
            stream = sd.RawInputStream(
                samplerate=RATE,
                channels=CHANNELS,
                dtype=DTYPE,
                blocksize=opts["blocksize"],
                device=input_device,  # pulse ÛŒØ§ default
                latency=opts["latency"],
            )
            stream.start()
            print(f"[AUDIO] Input stream opened (attempt {idx}): "
                  f"device={input_device}, blocksize={opts['blocksize']}, latency={opts['latency']}")
            return stream
        except sd.PortAudioError as e:
            last_err = e
            print(f"[AUDIO] Failed to open stream (attempt {idx}): {e}")
            # Ú©Ù…ÛŒ Ù…Ú©Ø« Ù‚Ø¨Ù„ Ø§Ø² ØªÙ„Ø§Ø´ Ø¨Ø¹Ø¯ÛŒ
            time.sleep(0.15)

    print("[FATAL] Could not open input stream after retries:", last_err)
    raise last_err


# ---------- Ø³Ø§Ø®Øª Ø±ÛŒÚ©Ø§Ú¯Ù†Ø§ÛŒØ²Ø±Ù‡Ø§ ----------
def build_wake_recognizer(model: Model) -> KaldiRecognizer:
    grammar = json.dumps([WAKE_WORD])
    rec = KaldiRecognizer(model, RATE, grammar)
    try:
        rec.SetWords(True)
        rec.SetMaxAlternatives(0)
    except Exception:
        pass
    print("[ASR] Wake grammar active:", grammar)
    return rec


def build_command_recognizer(model: Model) -> KaldiRecognizer:
    phrases = list(COMMANDS.keys())
    grammar = json.dumps(phrases)
    rec = KaldiRecognizer(model, RATE, grammar)
    try:
        rec.SetWords(True)
        rec.SetMaxAlternatives(0)
    except Exception:
        pass
    print("[ASR] Strict grammar active:", grammar)
    return rec


def listen_command_exact(rec: KaldiRecognizer, stream_read, timeout_sec=COMMAND_TIMEOUT_SEC, silence_ms=FINAL_SILENCE_MS) -> str:
    start = time.time()
    last_voice_time = start
    time.sleep(0.35)  # Ø¬Ø¯Ø§ Ø´Ø¯Ù† tail ÙˆØ§Ú˜Ù‡ Ø¨ÛŒØ¯Ø§Ø±Ø¨Ø§Ø´
    try:
        rec.Reset()
    except Exception:
        pass

    exact_set = set(COMMANDS.keys())
    best_text = ""

    while True:
        data, _ = stream_read(BLOCKSIZE)
        if not data:
            if time.time() - start > timeout_sec:
                break
            continue

        buf = _as_bytes(data)
        accepted = rec.AcceptWaveform(buf)
        now = time.time()

        if accepted:
            res = json.loads(rec.Result())
            txt = (res.get("text") or "").strip()
            if txt:
                best_text = txt
                last_voice_time = now
                if txt in exact_set:
                    return txt

            if (now - last_voice_time) * 1000 >= silence_ms:
                return txt

        else:
            pres = json.loads(rec.PartialResult())
            ptxt = (pres.get("partial") or "").strip()
            if ptxt:
                last_voice_time = now

        if now - start > timeout_sec:
            break

    final = json.loads(rec.FinalResult()).get("text", "").strip()
    return final or best_text


def main():
    if not os.path.isdir(MODEL_PATH):
        print(f"[FATAL] Model not found at: {MODEL_PATH}")
        sys.exit(1)

    print("Loading Vosk model...", MODEL_PATH)
    model = Model(MODEL_PATH)

    # ---- Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ø§Ø³ØªØ±ÛŒÙ… ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§ fallbackÙ‡Ø§ÛŒ Ø§Ù…Ù† (Pulse/Default) ----
    stream = _open_input_stream()

    def _sigint_handler(sig, frame):
        print("\n[EXIT] Interrupted.")
        try:
            stream.stop()
            stream.close()
        except Exception:
            pass
        sys.exit(0)

    signal.signal(signal.SIGINT, _sigint_handler)

    print("ğŸ¤ Say something... (say 'nora' to wake)")
    add_state_listener(_on_state_update)
    add_control_listener(_on_control_event)
    request_state()

    wake_rec = build_wake_recognizer(model)
    listening_now = False

    def run_command_session(trigger_label: str = ""):
        nonlocal wake_rec, listening_now
        listening_now = True
        try:
            if trigger_label:
                print(trigger_label)
            rec_cmd = build_command_recognizer(model)
            cmd_text = listen_command_exact(
                rec_cmd,
                stream.read,
                timeout_sec=COMMAND_TIMEOUT_SEC,
                silence_ms=FINAL_SILENCE_MS,
            )
            print("ğŸ“¥ Full command (strict):", cmd_text if cmd_text else "<empty>")

            matched = handle_command(cmd_text)
            if matched:
                print("âœ… exact command executed")
            else:
                print("âŒ not an exact command (ignored)")
        finally:
            listening_now = False
            wake_rec = build_wake_recognizer(model)

    while True:
        try:
            if _manual_listen_event.is_set() and not listening_now:
                _manual_listen_event.clear()
                run_command_session("ğŸ§ Listening (UI request)")
                continue

            data, _ = stream.read(BLOCKSIZE)
            if not data:
                continue

            buf = _as_bytes(data)
            if not wake_word_enabled:
                continue

            if wake_rec.AcceptWaveform(buf):
                res = json.loads(wake_rec.Result())
                txt = (res.get("text") or "").strip()

                if txt == WAKE_WORD:
                    print(f"ğŸ”” Wake word detected: {WAKE_WORD}")
                    run_command_session()

        except KeyboardInterrupt:
            _sigint_handler(None, None)
        except sd.PortAudioError as e:
            # Ø§Ú¯Ø± Ø¯Ø± Ø­ÛŒÙ† Ú©Ø§Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ Ù‚Ø·Ø¹/Ù…Ø´ØºÙˆÙ„ Ø´Ø¯ØŒ ÛŒÚ©â€ŒØ¨Ø§Ø± Ø§Ø³ØªØ±ÛŒÙ… Ø±Ø§ Ø¨Ø§ fallbackÙ‡Ø§ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ø§Ø² Ú©Ù†
            print("[AUDIO] PortAudioError in main loop, reopening stream:", e)
            try:
                stream.stop()
                stream.close()
            except Exception:
                pass
            time.sleep(0.2)
            stream = _open_input_stream()
            wake_rec = build_wake_recognizer(model)
        except Exception as e:
            print("[ERROR] Main loop exception:", e)
            traceback.print_exc()
            time.sleep(0.2)


if __name__ == "__main__":
    main()
